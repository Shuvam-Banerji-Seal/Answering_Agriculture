{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eae811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66764e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "LOGIN_TOKEN=os.getenv(\"login_token\")\n",
    "\n",
    "login(token=LOGIN_TOKEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f27d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config= BitsAndBytesConfig(load_in_8bit=True)\n",
    "use_quantization_config= False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "attention_implementation= 'eager'\n",
    "model_id='google/gemma-3-1b-it'\n",
    "tokenizer=AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id,padding_side=\"left\")\n",
    "llm_model=AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
    "                                        torch_dtype=torch.bfloat16,\n",
    "                                        quantization_config=quantization_config if use_quantization_config else None\n",
    "                                        ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677151ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gen(query:str):\n",
    "    base_prompt=f\"\"\" \n",
    "You are a query expansion specialist for a retrieval system. Your task is to generate multiple search variations of the original query to maximize retrieval of relevant documents.\n",
    "\n",
    "**Original Query:** \"{query}\"\n",
    "\n",
    "Generate exactly 5 expanded queries following these guidelines:\n",
    "\n",
    "1. **Synonym Variation**: Replace key terms with synonyms and alternative phrasings\n",
    "2. **Technical Reformulation**: Use domain-specific terminology and technical language\n",
    "3. **Simplified Version**: Rephrase using common, everyday language\n",
    "4. **Context Expansion**: Add implicit context or background information that might be relevant\n",
    "5. **Perspective Shift**: Approach the same information need from a different angle or use case\n",
    "\n",
    "**Requirements:**\n",
    "- Keep the core intent and meaning unchanged\n",
    "- Each variation should be 1-2 sentences maximum\n",
    "- Focus on terms that would appear in relevant documents\n",
    "- Avoid redundant variations\n",
    "- Prioritize searchable keywords over conversational language\n",
    "\n",
    "**Output Format:**\n",
    "1. [Synonym variation]\n",
    "2. [Technical version]\n",
    "3. [Simplified version]  \n",
    "4. [Context expanded]\n",
    "5. [Perspective shifted]\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "    dialogue_template = [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": base_prompt}\n",
    "        ]\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7734431",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"why is the protein content in rice is less\"\n",
    "prompt=prompt_gen(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7812c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             temperature=0.7,\n",
    "                             do_sample=True, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=1000) # how many new tokens to generate from prompt \n",
    "\n",
    "output_text = tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02f0112a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: why is the protein content in rice is less\n",
      "RAG answer:\n",
      "<bos>Okay, here are five expanded queries based on the original query \"why is the protein content in rice is less,\" following your guidelines:\n",
      "\n",
      "1.  \"What factors contribute to reduced protein levels in rice grains?\"\n",
      "2.  \"Rice protein yield and nutritional content – what’s the reason for the lower protein?\"\n",
      "3.  \"Low protein content in rice: causes and potential explanations.\"\n",
      "4.  \"Protein analysis of rice: exploring the reasons for diminished levels.\"\n",
      "5.  \"Impact of processing on rice protein – why is it less?\"<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "text=output_text.replace(prompt, '')\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3094ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "matches = re.findall(r\"^\\s*\\d+\\.\\s+\\\"(.*?)\\\"\", text, flags=re.MULTILINE)\n",
    "\n",
    "data=[]\n",
    "for num,m in enumerate(matches,start=1):\n",
    "    data.append({f\"query{num}\":m})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5639b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query1': 'What factors contribute to reduced protein levels in rice grains?'},\n",
       " {'query2': 'Rice protein yield and nutritional content – what’s the reason for the lower protein?'},\n",
       " {'query3': 'Low protein content in rice: causes and potential explanations.'},\n",
       " {'query4': 'Protein analysis of rice: exploring the reasons for diminished levels.'},\n",
       " {'query5': 'Impact of processing on rice protein – why is it less?'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
