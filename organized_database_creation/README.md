# Indian Agriculture Database Creation System

A comprehensive multi-agent system for creating structured datasets on Indian agriculture through intelligent web scraping and data curation. This repository contains two main approaches for collecting agriculture data from the internet.

## üåæ Overview

This system was designed to create comprehensive datasets for Retrieval-Augmented Generation (RAG) pipelines focused on Indian agriculture. It employs two distinct but complementary approaches to gather data from across the internet:

1. **Keyword-Based Search Approach** - Systematic searches using predefined agriculture-related queries
2. **Autonomous Agentic Search Approach** - Intelligent agents that autonomously generate and execute searches

## üìä System Architecture

```
Internet Sources (Global Web)
         ‚Üì
   Search Engines (DuckDuckGo)
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Keyword-Based  ‚îÇ  Autonomous     ‚îÇ
‚îÇ  Search System  ‚îÇ  Agent System   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì
   Content Processing
         ‚Üì
   Data Structuring
         ‚Üì
   JSONL Dataset Output
```

## üéØ Two Main Approaches

### 1. Keyword-Based Search Approach

**Location**: `keyword_based_search/`

A systematic approach using predefined search queries covering all aspects of Indian agriculture.

**Key Features**:
- 60+ predefined search queries
- 4-20 parallel agents processing queries
- Specialized agent roles (crop production, sustainable farming, policy, technology)
- Fixed search patterns with regional and crop-specific modifications

**Search Categories**:
- Crops: Rice, wheat, cotton, sugarcane, pulses, millets, spices, fruits, vegetables
- Regions: All 28 Indian states and agricultural zones
- Methods: Organic farming, precision agriculture, irrigation, soil management
- Economics: Agricultural policies, subsidies, market dynamics

### 2. Autonomous Agentic Search Approach

**Location**: `autonomous_agent_search/`

An intelligent system where agents autonomously generate search queries and adapt their strategies.

**Key Features**:
- 12+ specialized autonomous agents
- Unlimited dynamic query generation
- Self-learning and adaptive search strategies
- Cross-agent coordination and deduplication
- Real-time processing and immediate data writing

**Agent Specializations**:
1. Crop Science & Plant Breeding
2. Soil Science & Fertility Management
3. Water Resources & Irrigation
4. Plant Protection & Pest Management
5. Agricultural Technology & Precision Farming
6. Sustainable & Organic Farming
7. Agricultural Economics & Policy
8. Climate Change & Adaptation
9. Horticulture & Plantation Crops
10. Livestock & Animal Husbandry
11. Food Processing & Post-Harvest
12. Rural Development & Extension

## üìÅ Repository Structure

```
organized_database_creation/
‚îú‚îÄ‚îÄ README.md                           # This file
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ keyword_approach_diagram.md    # Keyword approach workflow
‚îÇ   ‚îú‚îÄ‚îÄ autonomous_approach_diagram.md # Autonomous approach workflow
‚îÇ   ‚îú‚îÄ‚îÄ data_format_specification.md   # Output data format details
‚îÇ   ‚îî‚îÄ‚îÄ comparison_analysis.md         # Approach comparison
‚îú‚îÄ‚îÄ keyword_based_search/              # Keyword-based approach
‚îÇ   ‚îú‚îÄ‚îÄ README.md                      # Keyword approach documentation
‚îÇ   ‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agriculture_data_curator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agriculture_curator_fixed.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ enhanced_web_search.py
‚îÇ   ‚îú‚îÄ‚îÄ config/                       # Configuration files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ search_queries.py
‚îÇ   ‚îú‚îÄ‚îÄ tests/                        # Test files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_installation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_fixed_curator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ examples.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt              # Dependencies
‚îú‚îÄ‚îÄ autonomous_agent_search/           # Autonomous approach
‚îÇ   ‚îú‚îÄ‚îÄ README.md                     # Autonomous approach documentation
‚îÇ   ‚îú‚îÄ‚îÄ src/                         # Source code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autonomous_agriculture_curator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autonomous_search_agent.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ knowledge_base.py
‚îÇ   ‚îú‚îÄ‚îÄ config/                      # Configuration files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autonomous_config.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent_specializations.py
‚îÇ   ‚îú‚îÄ‚îÄ tests/                       # Test files
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_autonomous.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ demo_autonomous.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt             # Dependencies
‚îú‚îÄ‚îÄ shared/                          # Shared utilities
‚îÇ   ‚îú‚îÄ‚îÄ pdf_processor.py            # PDF processing utilities
‚îÇ   ‚îú‚îÄ‚îÄ web_scraper.py              # Web scraping utilities
‚îÇ   ‚îú‚îÄ‚îÄ data_validator.py           # Data validation
‚îÇ   ‚îî‚îÄ‚îÄ jsonl_writer.py             # JSONL output handling
‚îú‚îÄ‚îÄ sample_outputs/                  # Sample dataset outputs
‚îÇ   ‚îú‚îÄ‚îÄ keyword_sample.jsonl        # Sample from keyword approach
‚îÇ   ‚îú‚îÄ‚îÄ autonomous_sample.jsonl     # Sample from autonomous approach
‚îÇ   ‚îî‚îÄ‚îÄ combined_sample.jsonl       # Combined dataset sample
‚îî‚îÄ‚îÄ setup/                          # Setup and installation
    ‚îú‚îÄ‚îÄ setup.py                    # Automated setup script
    ‚îú‚îÄ‚îÄ install_dependencies.sh     # Dependency installation
    ‚îî‚îÄ‚îÄ system_requirements.md      # System requirements
```

## üîÑ Data Flow Diagrams

### Keyword-Based Search Flow

```mermaid
graph TD
    A[Predefined Search Queries] --> B[Agent Assignment]
    B --> C[Parallel Web Search]
    C --> D[Content Extraction]
    D --> E[Relevance Scoring]
    E --> F[Data Structuring]
    F --> G[JSONL Output]
    
    H[Search Categories] --> A
    I[Regional Modifiers] --> A
    J[Crop Specifications] --> A
```

### Autonomous Agent Search Flow

```mermaid
graph TD
    A[Knowledge Base] --> B[Dynamic Query Generation]
    B --> C[Agent Specialization]
    C --> D[Autonomous Web Search]
    D --> E[Content Processing]
    E --> F[Learning & Adaptation]
    F --> G[Cross-Agent Coordination]
    G --> H[Real-time JSONL Writing]
    
    I[Search History] --> F
    J[Success Patterns] --> F
    K[Domain Preferences] --> F
```

## üìã Data Format Specification

Each entry in the output JSONL files contains:

```json
{
  "title": "Content title",
  "author": "Author if available",
  "link": "Source URL",
  "text_extracted": "Full extracted content",
  "abstract": "Brief summary",
  "genre": "survey|dataset|pdf|book|report|article",
  "tags": ["relevant", "agriculture", "tags"],
  "indian_regions": ["Punjab", "Maharashtra"],
  "crop_types": ["rice", "wheat"],
  "farming_methods": ["organic", "irrigation"],
  "soil_types": ["black", "alluvial"],
  "climate_info": ["tropical", "monsoon"],
  "fertilizers": ["organic", "NPK"],
  "data_type": "statistical|qualitative|mixed",
  "publication_year": 2023,
  "source_domain": "icar.org.in",
  "extraction_timestamp": "2025-08-09T10:30:45",
  "relevance_score": 0.85,
  "content_length": 3245,
  "content_hash": "unique_hash",
  "url_hash": "unique_url_hash",
  "is_pdf": false,
  "pdf_path": null
}
```

## üöÄ Quick Start

### Prerequisites

1. **Python 3.9+**
2. **Required packages** (see requirements.txt in each approach)
3. **System dependencies** for PDF processing and OCR

### Installation

```bash
# Clone or download the repository
cd organized_database_creation

# Install dependencies for both approaches
pip install -r keyword_based_search/requirements.txt
pip install -r autonomous_agent_search/requirements.txt

# Run setup script
python setup/setup.py
```

### Running the Systems

**Keyword-Based Approach:**
```bash
cd keyword_based_search
python src/agriculture_data_curator.py
```

**Autonomous Agent Approach:**
```bash
cd autonomous_agent_search
python src/autonomous_agriculture_curator.py
```

## üìä Expected Outputs

### Keyword-Based Approach
- **Data Volume**: 500-2,000 structured entries
- **Coverage**: Systematic coverage of predefined categories
- **Quality**: High relevance due to targeted searches
- **Processing Time**: 2-6 hours depending on configuration

### Autonomous Agent Approach
- **Data Volume**: 5,000-15,000+ structured entries
- **Coverage**: Comprehensive and adaptive coverage
- **Quality**: High diversity with intelligent filtering
- **Processing Time**: 4-12 hours depending on agent count

## üîç Approach Comparison

| Aspect | Keyword-Based | Autonomous Agent |
|--------|---------------|------------------|
| **Search Strategy** | Predefined queries | Dynamic generation |
| **Scalability** | Limited by query set | Unlimited expansion |
| **Coverage** | Systematic | Comprehensive |
| **Adaptability** | Fixed patterns | Self-learning |
| **Resource Usage** | Moderate | Higher |
| **Data Volume** | 500-2K entries | 5K-15K+ entries |
| **Setup Complexity** | Simple | Moderate |
| **Customization** | Query modification | Agent specialization |

## üéØ Use Cases

### When to Use Keyword-Based Approach
- **Targeted data collection** for specific agriculture domains
- **Limited computational resources**
- **Quick prototyping** and testing
- **Specific research questions** with known parameters

### When to Use Autonomous Agent Approach
- **Comprehensive dataset creation** for RAG systems
- **Exploratory data collection** across all agriculture domains
- **Large-scale data requirements**
- **Continuous data collection** with adaptive strategies

## üîß Customization

### Keyword-Based Customization
- Modify `config/search_queries.py` to add new search patterns
- Adjust `config/config.yaml` for processing parameters
- Customize agent specializations in source code

### Autonomous Agent Customization
- Edit `config/autonomous_config.yaml` for agent behavior
- Modify knowledge base in `src/knowledge_base.py`
- Add new agent specializations in configuration

## üìà Performance Metrics

### Data Quality Metrics
- **Relevance Score**: 0.0-1.0 based on agriculture content
- **Content Length**: Minimum thresholds for meaningful content
- **Source Diversity**: Coverage across government, academic, and research sources
- **Temporal Coverage**: Mix of historical and recent publications

### System Performance
- **Processing Speed**: Entries per hour
- **Success Rate**: Successful extractions vs attempts
- **Duplicate Rate**: Percentage of duplicate content detected
- **Error Rate**: Failed processing attempts

## üõ†Ô∏è Technical Dependencies

### Core Dependencies
- **requests**: HTTP requests and web scraping
- **duckduckgo-search**: Search engine integration
- **beautifulsoup4**: HTML parsing and content extraction
- **lxml**: XML/HTML processing

### PDF Processing
- **pypdf2**: PDF text extraction
- **pymupdf**: Advanced PDF processing
- **pytesseract**: OCR for scanned documents
- **pillow**: Image processing

### Data Processing
- **pyyaml**: Configuration file parsing
- **python-magic**: File type detection
- **hashlib**: Content deduplication

## üîí Data Privacy and Ethics

### Ethical Considerations
- **Robots.txt Compliance**: Respects website crawling policies
- **Rate Limiting**: Prevents server overload
- **Source Attribution**: Maintains original source links
- **Content Licensing**: Respects copyright and fair use

### Data Quality Assurance
- **Relevance Filtering**: Agriculture-specific content validation
- **Duplicate Detection**: URL and content-based deduplication
- **Source Verification**: Priority scoring for trusted domains
- **Content Validation**: Length and quality thresholds

## ü§ù Contributing

### Adding New Features
1. **New Search Strategies**: Implement in respective approach directories
2. **Enhanced Processing**: Add to shared utilities
3. **Output Formats**: Extend data format specifications
4. **Quality Improvements**: Enhance filtering and validation

### Testing
- Run test suites in each approach directory
- Validate output format compliance
- Test with different configuration parameters
- Monitor system performance and resource usage

## üìÑ License

This project is designed for research and educational purposes. Please respect website terms of service and copyright when using the scraped data.

## üôè Acknowledgments

- **Heavy Ollama Project**: Inspiration for multi-agent architecture
- **Indian Agricultural Research Community**: Source of valuable data
- **Open Source Libraries**: Essential tools for web scraping and data processing

---

**Note**: This system is designed for research purposes. Always ensure compliance with website terms of service and respect rate limiting when scraping data.